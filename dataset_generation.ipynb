{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21312592-5891-4fc4-b3cc-c39f6c6d9d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 38833 timestamps from 2023-01-01 00:00:00 to 2025-03-20 00:00:00\n",
      "Service groups: ['Social Media', 'Gaming', 'Streaming', 'Shopping', 'Software']\n",
      "Dataset saved to network_dataset.csv\n",
      "Generated 38833 records with 5 service groups\n",
      "\n",
      "Summary by Service Group:\n",
      "Streaming: 9133 records, Avg Bandwidth: 57.61 Mbps\n",
      "Shopping: 6148 records, Avg Bandwidth: 10.41 Mbps\n",
      "Software: 9609 records, Avg Bandwidth: 21.52 Mbps\n",
      "Gaming: 6574 records, Avg Bandwidth: 27.15 Mbps\n",
      "Social Media: 7369 records, Avg Bandwidth: 16.00 Mbps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def generate_mac_address():\n",
    "    \"\"\"Generate a random MAC address\"\"\"\n",
    "    # Generate 6 random bytes\n",
    "    mac_bytes = [random.randint(0, 255) for _ in range(6)]\n",
    "    # Format as MAC address (XX:XX:XX:XX:XX:XX)\n",
    "    mac_address = ':'.join([f'{b:02X}' for b in mac_bytes])\n",
    "    return mac_address\n",
    "\n",
    "def generate_network_dataset(output_path='network_dataset.csv', start_date=datetime(2023, 1, 1), \n",
    "                            end_date=datetime(2025, 3, 20), interval_minutes=30):\n",
    "    \"\"\"\n",
    "    Generate synthetic network dataset with comprehensive network signals\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    output_path : str\n",
    "        Path to save the CSV file\n",
    "    start_date : datetime\n",
    "        Start date for dataset\n",
    "    end_date : datetime\n",
    "        End date for dataset\n",
    "    interval_minutes : int\n",
    "        Time interval between data points in minutes\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "        The generated dataset\n",
    "    \"\"\"\n",
    "    # Define the date range and intervals\n",
    "    date_range = pd.date_range(start=start_date, end=end_date, freq=f'{interval_minutes}T')\n",
    "    \n",
    "    # Define service groups and their service names\n",
    "    service_groups = {\n",
    "        \"Social Media\": [\"Instagram\", \"Facebook\", \"LinkedIn\", \"Twitter\"],\n",
    "        \"Gaming\": [\"Fortnite\", \"League of Legends\", \"Valorant\"],\n",
    "        \"Streaming\": [\"YouTube\", \"Netflix\", \"Disney+\"],\n",
    "        \"Shopping\": [\"Amazon\", \"Etsy\", \"eBay\", \"Walmart\"],\n",
    "        \"Software\": [\"Gmail\", \"Slack\", \"WebEx\", \"GMeet\"]\n",
    "    }\n",
    "    \n",
    "    # Create group_id and service_id maps\n",
    "    group_ids = {group: 1001 + i for i, group in enumerate(service_groups)}\n",
    "    service_ids = {}\n",
    "    for group in service_groups:\n",
    "        for i, service in enumerate(service_groups[group]):\n",
    "            # Generate unique service IDs within each group\n",
    "            base_id = (group_ids[group] - 1000) * 100\n",
    "            service_ids[service] = base_id + i + 1\n",
    "    \n",
    "    print(f\"Generating {len(date_range)} timestamps from {start_date} to {end_date}\")\n",
    "    print(f\"Service groups: {list(service_groups.keys())}\")\n",
    "    \n",
    "    # Data generation\n",
    "    data = []\n",
    "    for timestamp in date_range:\n",
    "        # Generate a unique MAC address for this session\n",
    "        mac_address = generate_mac_address()\n",
    "        \n",
    "        # Time-based logic for service group probabilities\n",
    "        hour = timestamp.hour\n",
    "        is_weekend = timestamp.weekday() >= 5\n",
    "        \n",
    "        # Adjust probabilities based on time of day and day of week\n",
    "        if 9 <= hour <= 17 and not is_weekend:\n",
    "            # Work hours on weekdays\n",
    "            temp_probs = {\n",
    "                \"Social Media\": 0.15,\n",
    "                \"Gaming\": 0.05,\n",
    "                \"Streaming\": 0.10,\n",
    "                \"Shopping\": 0.15,\n",
    "                \"Software\": 0.55\n",
    "            }\n",
    "        elif 18 <= hour <= 23:\n",
    "            # Evening hours\n",
    "            temp_probs = {\n",
    "                \"Social Media\": 0.15,\n",
    "                \"Gaming\": 0.30,\n",
    "                \"Streaming\": 0.35,\n",
    "                \"Shopping\": 0.15,\n",
    "                \"Software\": 0.05\n",
    "            }\n",
    "        elif is_weekend:\n",
    "            # Weekend\n",
    "            temp_probs = {\n",
    "                \"Social Media\": 0.20,\n",
    "                \"Gaming\": 0.25,\n",
    "                \"Streaming\": 0.30,\n",
    "                \"Shopping\": 0.20,\n",
    "                \"Software\": 0.05\n",
    "            }\n",
    "        else:\n",
    "            # Default - early morning\n",
    "            temp_probs = {\n",
    "                \"Social Media\": 0.25,\n",
    "                \"Gaming\": 0.10,\n",
    "                \"Streaming\": 0.20,\n",
    "                \"Shopping\": 0.15,\n",
    "                \"Software\": 0.30\n",
    "            }\n",
    "        \n",
    "        # Determine service group based on adjusted probabilities\n",
    "        service_group = random.choices(\n",
    "            list(temp_probs.keys()), \n",
    "            weights=list(temp_probs.values())\n",
    "        )[0]\n",
    "        \n",
    "        # Select specific service within group\n",
    "        service_name = random.choice(service_groups[service_group])\n",
    "        \n",
    "        # Network metrics generation based on service group\n",
    "        if service_group == \"Streaming\":\n",
    "            bandwidth = round(random.uniform(15, 100), 2)\n",
    "            signal_strength = round(random.uniform(-70, -30), 2)\n",
    "            packet_loss = round(random.uniform(0, 0.2), 4)\n",
    "            latency = round(random.uniform(10, 50), 2)\n",
    "            jitter = round(random.uniform(1, 5), 2)\n",
    "        elif service_group == \"Gaming\":\n",
    "            bandwidth = round(random.uniform(5, 50), 2)\n",
    "            signal_strength = round(random.uniform(-65, -25), 2)\n",
    "            packet_loss = round(random.uniform(0, 0.1), 4)\n",
    "            latency = round(random.uniform(5, 30), 2)\n",
    "            jitter = round(random.uniform(0.5, 3), 2)\n",
    "        elif service_group == \"Social Media\":\n",
    "            bandwidth = round(random.uniform(2, 30), 2)\n",
    "            signal_strength = round(random.uniform(-75, -40), 2)\n",
    "            packet_loss = round(random.uniform(0, 0.3), 4)\n",
    "            latency = round(random.uniform(20, 80), 2)\n",
    "            jitter = round(random.uniform(2, 8), 2)\n",
    "        elif service_group == \"Shopping\":\n",
    "            bandwidth = round(random.uniform(1, 20), 2)\n",
    "            signal_strength = round(random.uniform(-80, -45), 2)\n",
    "            packet_loss = round(random.uniform(0, 0.4), 4)\n",
    "            latency = round(random.uniform(30, 100), 2)\n",
    "            jitter = round(random.uniform(3, 10), 2)\n",
    "        else:  # Software\n",
    "            bandwidth = round(random.uniform(3, 40), 2)\n",
    "            signal_strength = round(random.uniform(-70, -35), 2)\n",
    "            packet_loss = round(random.uniform(0, 0.2), 4)\n",
    "            latency = round(random.uniform(15, 70), 2)\n",
    "            jitter = round(random.uniform(1, 7), 2)\n",
    "        \n",
    "        # Temporal features\n",
    "        hour = timestamp.hour\n",
    "        day_of_week = timestamp.weekday()\n",
    "        month = timestamp.month\n",
    "        \n",
    "        # Usage metrics\n",
    "        usage_percentage = round(random.uniform(10, 90), 2)\n",
    "        usage_minutes = round(usage_percentage * 0.3, 2)  # Proportional to percentage\n",
    "        \n",
    "        # Device group (work devices more likely during work hours)\n",
    "        if service_group == \"Software\" and 8 <= hour <= 18 and day_of_week < 5:\n",
    "            device_group = \"work_device\"\n",
    "        else:\n",
    "            device_group = \"personal_device\"\n",
    "        \n",
    "        data.append([\n",
    "            timestamp, \n",
    "            service_group, \n",
    "            group_ids[service_group],\n",
    "            service_name, \n",
    "            service_ids[service_name],\n",
    "            bandwidth,\n",
    "            signal_strength,\n",
    "            packet_loss,\n",
    "            latency,\n",
    "            jitter,\n",
    "            hour,\n",
    "            day_of_week,\n",
    "            month,\n",
    "            usage_percentage,\n",
    "            usage_minutes,\n",
    "            device_group,\n",
    "            mac_address\n",
    "        ])\n",
    "    \n",
    "    # Create DataFrame\n",
    "    columns = [\n",
    "        'timestamp', 'service_group', 'group_id', 'service_name', 'service_id', \n",
    "        'bandwidth_speed', 'signal_strength', 'packet_loss', 'latency', 'jitter',\n",
    "        'hour', 'day_of_week', 'month', \n",
    "        'usage_percentage', 'usage_minutes', 'device_group', 'mac_address'\n",
    "    ]\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Dataset saved to {output_path}\")\n",
    "    print(f\"Generated {len(df)} records with {len(df['service_group'].unique())} service groups\")\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    print(\"\\nSummary by Service Group:\")\n",
    "    for group in df['service_group'].unique():\n",
    "        group_data = df[df['service_group'] == group]\n",
    "        print(f\"{group}: {len(group_data)} records, \" +\n",
    "              f\"Avg Bandwidth: {group_data['bandwidth_speed'].mean():.2f} Mbps\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_training_testing_datasets(output_dir='data', \n",
    "                                      train_file='train_network_data.csv',\n",
    "                                      test_file='test_network_data.csv',\n",
    "                                      train_start=datetime(2023, 1, 1),\n",
    "                                      train_end=datetime(2024, 12, 31),\n",
    "                                      test_start=datetime(2025, 1, 1),\n",
    "                                      test_end=datetime(2025, 3, 20)):\n",
    "    \"\"\"\n",
    "    Generate separate training and testing datasets\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    output_dir : str\n",
    "        Directory to save the datasets\n",
    "    train_file : str\n",
    "        Filename for the training data\n",
    "    test_file : str\n",
    "        Filename for the testing data\n",
    "    train_start : datetime\n",
    "        Start date for training data\n",
    "    train_end : datetime\n",
    "        End date for training data\n",
    "    test_start : datetime\n",
    "        Start date for testing data\n",
    "    test_end : datetime\n",
    "        End date for testing data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (train_df, test_df) - The training and testing DataFrames\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Generate training data\n",
    "    print(f\"Generating training data from {train_start} to {train_end}\")\n",
    "    train_df = generate_network_dataset(\n",
    "        os.path.join(output_dir, train_file), \n",
    "        start_date=train_start,\n",
    "        end_date=train_end\n",
    "    )\n",
    "    \n",
    "    # Generate testing data\n",
    "    print(f\"Generating testing data from {test_start} to {test_end}\")\n",
    "    test_df = generate_network_dataset(\n",
    "        os.path.join(output_dir, test_file),\n",
    "        start_date=test_start,\n",
    "        end_date=test_end\n",
    "    )\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate a dataset with custom date range\n",
    "    generate_network_dataset(\n",
    "        'network_dataset.csv',\n",
    "        start_date=datetime(2023, 1, 1),\n",
    "        end_date=datetime(2025, 3, 20),\n",
    "        interval_minutes=30\n",
    "    )\n",
    "    \n",
    "    # Optional: Generate separate training and testing datasets\n",
    "    # generate_training_testing_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daef1659-1f70-479e-8058-96c1d0c3bce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
